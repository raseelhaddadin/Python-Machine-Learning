{\rtf1\ansi\ansicpg1252\cocoartf2758
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red157\green0\blue210;\red255\green255\blue255;\red45\green45\blue45;
\red32\green108\blue135;\red101\green76\blue29;\red0\green0\blue109;\red0\green0\blue0;\red0\green0\blue255;
\red15\green112\blue1;\red144\green1\blue18;\red19\green118\blue70;\red230\green0\blue6;}
{\*\expandedcolortbl;;\cssrgb\c68627\c0\c85882;\cssrgb\c100000\c100000\c100000;\cssrgb\c23137\c23137\c23137;
\cssrgb\c14902\c49804\c60000;\cssrgb\c47451\c36863\c14902;\cssrgb\c0\c6275\c50196;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c100000;
\cssrgb\c0\c50196\c0;\cssrgb\c63922\c8235\c8235;\cssrgb\c3529\c52549\c34510;\cssrgb\c93333\c0\c0;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 numpy\cf4 \strokec4  \cf2 \strokec2 as\cf4 \strokec4  \cf5 \strokec5 np\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 pandas\cf4 \strokec4  \cf2 \strokec2 as\cf4 \strokec4  \cf5 \strokec5 pd\cf4 \cb1 \strokec4 \
\
\cf2 \cb3 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 datetime\cf4 \cb1 \strokec4 \
\
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 linear_model\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 LogisticRegression\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 tree\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 DecisionTreeClassifier\cf4 \strokec4  \cf2 \strokec2 as\cf4 \strokec4  \cf5 \strokec5 DecisionTree\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 model_selection\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf6 \strokec6 train_test_split\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 model_selection\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 GridSearchCV\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 metrics\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf6 \strokec6 accuracy_score\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 metrics\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf6 \strokec6 confusion_matrix\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 metrics\cf4 \cb1 \strokec4 \
\
\cf2 \cb3 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 seaborn\cf4 \strokec4  \cf2 \strokec2 as\cf4 \strokec4  \cf5 \strokec5 sns\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 sns\cf4 \strokec4 .\cf7 \strokec7 set\cf4 \strokec4 (\cf7 \strokec7 color_codes\cf4 \strokec8 =\cf9 \strokec9 True\cf4 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 matplotlib\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 matplotlib\cf4 \strokec4 .\cf5 \strokec5 pyplot\cf4 \strokec4  \cf2 \strokec2 as\cf4 \strokec4  \cf5 \strokec5 plt\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Loading the data\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 loan_data\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 pd\cf4 \strokec4 .\cf6 \strokec6 read_csv\cf4 \strokec4 (\cf11 \strokec11 './data/Lending_Club_sample_data.csv'\cf4 \strokec4 , \cf7 \strokec7 encoding\cf4 \strokec8 =\cf11 \strokec11 'latin-1'\cf4 \strokec4 )\cb1 \
\cf7 \cb3 \strokec7 loan_data\cf4 \strokec4 .\cf6 \strokec6 head\cf4 \strokec4 ()\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Part I Clean Up the Data\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 #Dropping columns we don't want & Dropping categorical data columns\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 # Delete addr_state, emp_title, id, member_id, , emp_length, pymnt_plan, title. so 7 columns \cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 loan_data\cf4 \strokec4 .\cf6 \strokec6 drop\cf4 \strokec4 ([\cf11 \strokec11 'addr_state'\cf4 \strokec4 ,\cf11 \strokec11 'emp_title'\cf4 \strokec4 ,\cf11 \strokec11 'id'\cf4 \strokec4 ,\cf11 \strokec11 'member_id'\cf4 \strokec4 , \cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3                 \cf11 \strokec11 'emp_length'\cf4 \strokec4 , \cf11 \strokec11 'pymnt_plan'\cf4 \strokec4 ,\cf11 \strokec11 'title'\cf4 \strokec4 ], \cf7 \strokec7 axis\cf4 \strokec4  \strokec8 =\strokec4  \cf12 \strokec12 1\cf4 \strokec4 , \cf7 \strokec7 inplace\cf4 \strokec4  \strokec8 =\strokec4  \cf9 \strokec9 True\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Look at the new dataframe with reduced columns\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 loan_data\cf4 \strokec4 .\cf6 \strokec6 head\cf4 \strokec4 ()\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Check for missing values\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 # Create a boolean dataframe\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 bool_df\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 loan_data\cf4 \strokec4 .\cf6 \strokec6 isnull\cf4 \strokec4 ()\cb1 \
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # Summing the missing values per column\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 num_miss_per_col\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 bool_df\cf4 \strokec4 .\cf6 \strokec6 sum\cf4 \strokec4 ()\cb1 \
\cf7 \cb3 \strokec7 num_miss_per_col\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Drop missing values\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 loan_data\cf4 \strokec4 .\cf6 \strokec6 dropna\cf4 \strokec4 (\cf7 \strokec7 inplace\cf4 \strokec4  \strokec8 =\strokec4  \cf9 \strokec9 True\cf4 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 len\cf4 \strokec4 (\cf7 \strokec7 loan_data\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Create dummies for categorical variables\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 loan_data_with_dummies_auto\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 pd\cf4 \strokec4 .\cf6 \strokec6 get_dummies\cf4 \strokec4 (\cf7 \strokec7 loan_data\cf4 \strokec4 , \cf7 \strokec7 drop_first\cf4 \strokec4  \strokec8 =\strokec4  \cf9 \strokec9 True\cf4 \strokec4 )\cb1 \
\cf7 \cb3 \strokec7 loan_data_with_dummies_auto\cf4 \strokec4 .\cf6 \strokec6 head\cf4 \strokec4 ()\cb1 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 list\cf4 \strokec4 (\cf7 \strokec7 loan_data_with_dummies_auto\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # We are keeping track of the column that was automatically dropped.\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 #Find the columns that were dropped\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 dropped_columns\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 set\cf4 \strokec4 (\cf7 \strokec7 loan_data\cf4 \strokec4 .\cf7 \strokec7 columns\cf4 \strokec4 ) \strokec8 -\strokec4  \cf5 \strokec5 set\cf4 \strokec4 (\cf7 \strokec7 loan_data_with_dummies_auto\cf4 \strokec4 .\cf7 \strokec7 columns\cf4 \strokec4 )\cb1 \
\cf7 \cb3 \strokec7 added_columns\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 set\cf4 \strokec4 (\cf7 \strokec7 loan_data_with_dummies_auto\cf4 \strokec4 .\cf7 \strokec7 columns\cf4 \strokec4 ) \strokec8 -\strokec4  \cf5 \strokec5 set\cf4 \strokec4 (\cf7 \strokec7 loan_data\cf4 \strokec4 .\cf7 \strokec7 columns\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 print\cf4 \strokec4 (\cf11 \strokec11 "Columns dropped during one-hot encoding:"\cf4 \strokec4 )\cb1 \
\cf6 \cb3 \strokec6 print\cf4 \strokec4 (\cf5 \strokec5 list\cf4 \strokec4 (\cf7 \strokec7 dropped_columns\cf4 \strokec4 ))\cb1 \
\
\cf6 \cb3 \strokec6 print\cf4 \strokec4 (\cf11 \strokec11 "\cf13 \strokec13 \\n\cf11 \strokec11 Columns added during one-hot encoding:"\cf4 \strokec4 )\cb1 \
\cf6 \cb3 \strokec6 print\cf4 \strokec4 (\cf5 \strokec5 list\cf4 \strokec4 (\cf7 \strokec7 added_columns\cf4 \strokec4 ))\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Separate the input characteristics (X) and the outocme variable (Y)\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 loan_data_with_dummies_auto_X\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 loan_data_with_dummies_auto\cf4 \strokec4 .\cf6 \strokec6 drop\cf4 \strokec4 (\cf11 \strokec11 'default_ind'\cf4 \strokec4 , \cf7 \strokec7 axis\cf4 \strokec8 =\cf12 \strokec12 1\cf4 \strokec4 )\cb1 \
\cf7 \cb3 \strokec7 loan_data_with_dummies_auto_Y\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 loan_data_with_dummies_auto\cf4 \strokec4 [\cf11 \strokec11 'default_ind'\cf4 \strokec4 ]\cb1 \
\cf7 \cb3 \strokec7 loan_data_X\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 loan_data\cf4 \strokec4 .\cf6 \strokec6 drop\cf4 \strokec4 (\cf11 \strokec11 'default_ind'\cf4 \strokec4 , \cf7 \strokec7 axis\cf4 \strokec8 =\cf12 \strokec12 1\cf4 \strokec4 )\cb1 \
\cf7 \cb3 \strokec7 loan_data_Y\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 loan_data\cf4 \strokec4 [\cf11 \strokec11 'default_ind'\cf4 \strokec4 ]\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Part III Split the Data\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 loan_train_X\cf4 \strokec4 , \cf7 \strokec7 loan_test_X\cf4 \strokec4 , \cf7 \strokec7 loan_train_Y\cf4 \strokec4 , \cf7 \strokec7 loan_test_Y\cf4 \strokec4  \strokec8 =\strokec4  \cf6 \strokec6 train_test_split\cf4 \strokec4 (\cf7 \strokec7 loan_data_with_dummies_auto_X\cf4 \strokec4 , \cf7 \strokec7 loan_data_with_dummies_auto_Y\cf4 \strokec4 , \cf7 \strokec7 random_state\cf4 \strokec4  \strokec8 =\strokec4  \cf12 \strokec12 42\cf4 \strokec4 , \cf7 \strokec7 train_size\cf4 \strokec4  \strokec8 =\strokec4  \cf12 \strokec12 0.7\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Part IV Learn the Classifiers\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf2 \cb3 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4  \cf2 \strokec2 as\cf4 \strokec4  \cf5 \strokec5 skl\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 linear_model\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 LogisticRegression\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 tree\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 DecisionTreeClassifier\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 model_selection\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf6 \strokec6 train_test_split\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 metrics\cf4 \strokec4  \cf2 \strokec2 as\cf4 \strokec4  \cf5 \strokec5 sklmetrics\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 from\cf4 \strokec4  \cf5 \strokec5 sklearn\cf4 \strokec4 .\cf5 \strokec5 model_selection\cf4 \strokec4  \cf2 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 GridSearchCV\cf4 \cb1 \strokec4 \
\cf2 \cb3 \strokec2 import\cf4 \strokec4  \cf5 \strokec5 warnings\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 warnings\cf4 \strokec4 .\cf6 \strokec6 filterwarnings\cf4 \strokec4 (\cf11 \strokec11 'ignore'\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Logistic Regression Classifier\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 # Step 0\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 model\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 LogisticRegression\cf4 \strokec4 (\cf7 \strokec7 class_weight\cf4 \strokec8 =\cf11 \strokec11 'balanced'\cf4 \strokec4 , \cf7 \strokec7 solver\cf4 \strokec4  \strokec8 =\strokec4  \cf11 \strokec11 'liblinear'\cf4 \strokec4 , \cf7 \strokec7 random_state\cf4 \strokec4  \strokec8 =\strokec4  \cf12 \strokec12 42\cf4 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # Step 1: Specify the dictionary of the parameters \cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 params\cf4 \strokec4  \strokec8 =\strokec4  \{\cf11 \strokec11 'penalty'\cf4 \strokec4 :[\cf11 \strokec11 'l1'\cf4 \strokec4 ,\cf11 \strokec11 'l2'\cf4 \strokec4 ],\cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3           \cf11 \strokec11 'C'\cf4 \strokec4 :[\cf12 \strokec12 0.01\cf4 \strokec4 , \cf12 \strokec12 0.1\cf4 \strokec4 , \cf12 \strokec12 1\cf4 \strokec4 , \cf12 \strokec12 10\cf4 \strokec4 , \cf12 \strokec12 100\cf4 \strokec4 ]\}\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # Step 2: Prepare the GridSearch for cross validation\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 grid_search_log_reg\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 GridSearchCV\cf4 \strokec4 (\cf7 \strokec7 model\cf4 \strokec4 , \cf10 \strokec10 # Note the model is DecisionTreeClassifier as stated above\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3                                     \cf7 \strokec7 param_grid\cf4 \strokec8 =\cf7 \strokec7 params\cf4 \strokec4 , \cf10 \strokec10 # The parameters to search over. \cf4 \cb1 \strokec4 \
\cb3                                    \cf7 \strokec7 cv\cf4 \strokec8 =\cf12 \strokec12 10\cf4 \strokec4 , \cf10 \strokec10 # How many hold out sets to use\cf4 \cb1 \strokec4 \
\cb3                                    \cf7 \strokec7 n_jobs\cf4 \strokec4  \strokec8 =\strokec4  \cf12 \strokec12 5\cf4 \strokec4  \cf10 \strokec10 # Number of parallel processes to run. \cf4 \cb1 \strokec4 \
\cb3                                    )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # Step 3: Do the cross validation on the training data \cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 grid_search_log_reg\cf4 \strokec4 .\cf6 \strokec6 fit\cf4 \strokec4 (\cf7 \strokec7 loan_train_X\cf4 \strokec4 , \cf7 \strokec7 loan_train_Y\cf4 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # Step 4: Select the best model\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 best_log_reg_cv\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 grid_search_log_reg\cf4 \strokec4 .\cf7 \strokec7 best_estimator_\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # Step 4.1: Print the best parameter combination \cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 print\cf4 \strokec4 (\cf7 \strokec7 grid_search_log_reg\cf4 \strokec4 .\cf7 \strokec7 best_params_\cf4 \strokec4 ) \cf10 \strokec10 # \{'C': 1, 'penalty': 'l1'\}\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Decision Tree Classifier\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 # For decision tree based classification\cf4 \cb1 \strokec4 \
\
\cf10 \cb3 \strokec10 # The model you want to set the parameters for\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 model\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 DecisionTreeClassifier\cf4 \strokec4 (\cf7 \strokec7 class_weight\cf4 \strokec8 =\cf11 \strokec11 'balanced'\cf4 \strokec4 , \cf7 \strokec7 random_state\cf4 \strokec8 =\cf12 \strokec12 42\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # The parameters to search over for the model\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 params\cf4 \strokec4  \strokec8 =\strokec4  \{\cf11 \strokec11 'max_depth'\cf4 \strokec4 :[\cf12 \strokec12 2\cf4 \strokec4 ,\cf12 \strokec12 3\cf4 \strokec4 ,\cf12 \strokec12 4\cf4 \strokec4 ],\cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3           \cf11 \strokec11 'max_features'\cf4 \strokec4 :[\cf11 \strokec11 'auto'\cf4 \strokec4 ,\cf11 \strokec11 'log2'\cf4 \strokec4 ,\cf9 \strokec9 None\cf4 \strokec4 ]\}\cb1 \
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # Prepare the GridSearch for cross validation\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 grid_search_dec_tree\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 GridSearchCV\cf4 \strokec4 (\cf7 \strokec7 model\cf4 \strokec4 , \cf10 \strokec10 # Note the model is DecisionTreeClassifier as stated above\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3                                     \cf7 \strokec7 param_grid\cf4 \strokec8 =\cf7 \strokec7 params\cf4 \strokec4 , \cf10 \strokec10 # The parameters to search over. \cf4 \cb1 \strokec4 \
\cb3                                    \cf7 \strokec7 cv\cf4 \strokec8 =\cf12 \strokec12 10\cf4 \strokec4 , \cf10 \strokec10 # How many hold out sets to use\cf4 \cb1 \strokec4 \
\cb3                                    \cf7 \strokec7 n_jobs\cf4 \strokec4  \strokec8 =\strokec4  \cf12 \strokec12 1\cf4 \strokec4  \cf10 \strokec10 # Number of parallel processes to run. \cf4 \cb1 \strokec4 \
\cb3                                    )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # Do the cross validation on the training data \cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 grid_search_dec_tree\cf4 \strokec4 .\cf6 \strokec6 fit\cf4 \strokec4 (\cf7 \strokec7 loan_train_X\cf4 \strokec4 , \cf7 \strokec7 loan_train_Y\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # Select the best model\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 best_dec_tree_cv\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 grid_search_dec_tree\cf4 \strokec4 .\cf7 \strokec7 best_estimator_\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 # Print the best parameter combination \cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 print\cf4 \strokec4 (\cf7 \strokec7 grid_search_dec_tree\cf4 \strokec4 .\cf7 \strokec7 best_params_\cf4 \strokec4 ) \cf10 \strokec10 # 'max_depth': 4, 'max_features': None\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Part V Testing Performance of Classifiers\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 #Logistic Regression - Testing Performance of the Best Model on Test Data\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 loan_predict_Y\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 best_log_reg_cv\cf4 \strokec4 .\cf6 \strokec6 predict\cf4 \strokec4 (\cf7 \strokec7 loan_test_X\cf4 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 print\cf4 \strokec4 (\cf11 \strokec11 "The accuracy is \cf9 \strokec9 \{0\}\cf11 \strokec11 "\cf4 \strokec4 .\cf6 \strokec6 format\cf4 \strokec4 (\cf5 \strokec5 sklmetrics\cf4 \strokec4 .\cf6 \strokec6 accuracy_score\cf4 \strokec4 (\cf7 \strokec7 loan_test_Y\cf4 \strokec4 , \cf7 \strokec7 loan_predict_Y\cf4 \strokec4 )))\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 conf_mat\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 sklmetrics\cf4 \strokec4 .\cf6 \strokec6 confusion_matrix\cf4 \strokec4 (\cf7 \strokec7 loan_test_Y\cf4 \strokec4 , \cf7 \strokec7 loan_predict_Y\cf4 \strokec4 , \cf7 \strokec7 labels\cf4 \strokec4  \strokec8 =\strokec4 [\cf12 \strokec12 0\cf4 \strokec4 ,\cf12 \strokec12 1\cf4 \strokec4 ])\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 print\cf4 \strokec4 (\cf7 \strokec7 conf_mat\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 sns\cf4 \strokec4 .\cf6 \strokec6 heatmap\cf4 \strokec4 (\cf7 \strokec7 conf_mat\cf4 \strokec4 , \cf7 \strokec7 square\cf4 \strokec8 =\cf9 \strokec9 True\cf4 \strokec4 , \cf7 \strokec7 annot\cf4 \strokec8 =\cf9 \strokec9 True\cf4 \strokec4 , \cf7 \strokec7 cbar\cf4 \strokec4  \strokec8 =\strokec4  \cf9 \strokec9 False\cf4 \strokec4 , \cf7 \strokec7 xticklabels\cf4 \strokec4  \strokec8 =\strokec4  [\cf11 \strokec11 'Not Defaulted'\cf4 \strokec4 ,\cf11 \strokec11 'Defaulted'\cf4 \strokec4 ], \cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3             \cf7 \strokec7 yticklabels\cf4 \strokec4  \strokec8 =\strokec4  [\cf11 \strokec11 'Not Defaulted'\cf4 \strokec4 ,\cf11 \strokec11 'Defaulted'\cf4 \strokec4 ], \cf7 \strokec7 fmt\cf4 \strokec4  \strokec8 =\strokec4  \cf11 \strokec11 'g'\cf4 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 xlabel\cf4 \strokec4 (\cf11 \strokec11 "Predicted Value"\cf4 \strokec4 )\cb1 \
\cf5 \cb3 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 ylabel\cf4 \strokec4 (\cf11 \strokec11 "True Value"\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Decision Tree - Testing Performance of the Best Model on Test Data\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 loan_predict_Y\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 best_dec_tree_cv\cf4 \strokec4 .\cf6 \strokec6 predict\cf4 \strokec4 (\cf7 \strokec7 loan_test_X\cf4 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 print\cf4 \strokec4 (\cf11 \strokec11 "The accuracy is \cf9 \strokec9 \{0\}\cf11 \strokec11 "\cf4 \strokec4 .\cf6 \strokec6 format\cf4 \strokec4 (\cf5 \strokec5 sklmetrics\cf4 \strokec4 .\cf6 \strokec6 accuracy_score\cf4 \strokec4 (\cf7 \strokec7 loan_test_Y\cf4 \strokec4 , \cf7 \strokec7 loan_predict_Y\cf4 \strokec4 )))\cb1 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb3 \strokec7 conf_mat\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 sklmetrics\cf4 \strokec4 .\cf6 \strokec6 confusion_matrix\cf4 \strokec4 (\cf7 \strokec7 loan_test_Y\cf4 \strokec4 , \cf7 \strokec7 loan_predict_Y\cf4 \strokec4 , \cf7 \strokec7 labels\cf4 \strokec4  \strokec8 =\strokec4 [\cf12 \strokec12 0\cf4 \strokec4 ,\cf12 \strokec12 1\cf4 \strokec4 ])\cb1 \
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 print\cf4 \strokec4 (\cf7 \strokec7 conf_mat\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 sns\cf4 \strokec4 .\cf6 \strokec6 heatmap\cf4 \strokec4 (\cf7 \strokec7 conf_mat\cf4 \strokec4 , \cf7 \strokec7 square\cf4 \strokec8 =\cf9 \strokec9 True\cf4 \strokec4 , \cf7 \strokec7 annot\cf4 \strokec8 =\cf9 \strokec9 True\cf4 \strokec4 , \cf7 \strokec7 cbar\cf4 \strokec4  \strokec8 =\strokec4  \cf9 \strokec9 False\cf4 \strokec4 , \cf7 \strokec7 xticklabels\cf4 \strokec4  \strokec8 =\strokec4  [\cf11 \strokec11 'Not Defaulted'\cf4 \strokec4 ,\cf11 \strokec11 'Defaulted'\cf4 \strokec4 ], \cb1 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb3             \cf7 \strokec7 yticklabels\cf4 \strokec4  \strokec8 =\strokec4  [\cf11 \strokec11 'Not Defaulted'\cf4 \strokec4 ,\cf11 \strokec11 'Defaulted'\cf4 \strokec4 ], \cf7 \strokec7 fmt\cf4 \strokec4  \strokec8 =\strokec4  \cf11 \strokec11 'g'\cf4 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb3 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 xlabel\cf4 \strokec4 (\cf11 \strokec11 "Predicted Value"\cf4 \strokec4 )\cb1 \
\cf5 \cb3 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 ylabel\cf4 \strokec4 (\cf11 \strokec11 "True Value"\cf4 \strokec4 )\cb1 \
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #cross validation, confusion matrix and then feature importance. \cf4 \cb1 \strokec4 \
\
\cf10 \cb3 \strokec10 #Logistic Regression - Plotting feature importance coefficients for the variables\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 # Defining a function to plot coefficients as feature importance\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 # INPUT: Used for Logistic Regression Classifier\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 #        Feature Names\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 # OUTPUT: A plot of top most Coefficients\cf4 \cb1 \strokec4 \
\pard\pardeftab720\partightenfactor0
\cf9 \cb3 \strokec9 def\cf4 \strokec4  \cf6 \strokec6 plot_feature_importance_coeff\cf4 \strokec4 (\cf7 \strokec7 model\cf4 \strokec4 , \cf7 \strokec7 Xnames\cf4 \strokec4 , \cf7 \strokec7 cls_nm\cf4 \strokec4  \strokec8 =\strokec4  \cf9 \strokec9 None\cf4 \strokec4 ):\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     \cf7 \strokec7 imp_features\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 pd\cf4 \strokec4 .\cf5 \strokec5 DataFrame\cf4 \strokec4 (\cf5 \strokec5 np\cf4 \strokec4 .\cf6 \strokec6 column_stack\cf4 \strokec4 ((\cf7 \strokec7 Xnames\cf4 \strokec4 , \cf7 \strokec7 model\cf4 \strokec4 .coef_.ravel())), \cf7 \strokec7 columns\cf4 \strokec4  \strokec8 =\strokec4  [\cf11 \strokec11 'feature'\cf4 \strokec4 , \cf11 \strokec11 'importance'\cf4 \strokec4 ])\cb1 \
\cb3     \cf7 \strokec7 imp_features\cf4 \strokec4 [[\cf11 \strokec11 'importance'\cf4 \strokec4 ]] \strokec8 =\strokec4  \cf7 \strokec7 imp_features\cf4 \strokec4 [[\cf11 \strokec11 'importance'\cf4 \strokec4 ]].\cf6 \strokec6 astype\cf4 \strokec4 (\cf5 \strokec5 float\cf4 \strokec4 )\cb1 \
\cb3     \cf7 \strokec7 imp_features\cf4 \strokec4 [[\cf11 \strokec11 'abs_importance'\cf4 \strokec4 ]] \strokec8 =\strokec4  \cf7 \strokec7 imp_features\cf4 \strokec4 [[\cf11 \strokec11 'importance'\cf4 \strokec4 ]].\cf6 \strokec6 abs\cf4 \strokec4 ()\cb1 \
\cb3     \cf10 \strokec10 # Sort the features based on absolute value of importance\cf4 \cb1 \strokec4 \
\cb3     \cf7 \strokec7 imp_features\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 imp_features\cf4 \strokec4 .\cf6 \strokec6 sort_values\cf4 \strokec4 (\cf7 \strokec7 by\cf4 \strokec4  \strokec8 =\strokec4  [\cf11 \strokec11 'abs_importance'\cf4 \strokec4 ], \cf7 \strokec7 ascending\cf4 \strokec4  \strokec8 =\strokec4  [\cf12 \strokec12 1\cf4 \strokec4 ])\cb1 \
\cb3     \cb1 \
\cb3     \cf10 \strokec10 # Plot the feature importances \cf4 \cb1 \strokec4 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 figure\cf4 \strokec4 (\cf7 \strokec7 figsize\cf4 \strokec8 =\strokec4 (\cf12 \strokec12 10\cf4 \strokec4 , \cf12 \strokec12 16\cf4 \strokec4 ))\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 title\cf4 \strokec4 (\cf7 \strokec7 cls_nm\cf4 \strokec4  \strokec8 +\strokec4  \cf11 \strokec11 " - Feature Importance"\cf4 \strokec4 )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 barh\cf4 \strokec4 (\cf5 \strokec5 range\cf4 \strokec4 (\cf7 \strokec7 imp_features\cf4 \strokec4 .shape[\cf12 \strokec12 0\cf4 \strokec4 ]), \cf7 \strokec7 imp_features\cf4 \strokec4 [\cf11 \strokec11 'importance'\cf4 \strokec4 ],\cb1 \
\cb3             \cf7 \strokec7 color\cf4 \strokec8 =\cf11 \strokec11 "b"\cf4 \strokec4 , \cf7 \strokec7 align\cf4 \strokec8 =\cf11 \strokec11 "center"\cf4 \strokec4 )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 yticks\cf4 \strokec4 (\cf5 \strokec5 range\cf4 \strokec4 (\cf7 \strokec7 imp_features\cf4 \strokec4 .shape[\cf12 \strokec12 0\cf4 \strokec4 ]), \cf7 \strokec7 imp_features\cf4 \strokec4 [\cf11 \strokec11 'feature'\cf4 \strokec4 ], )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 ylim\cf4 \strokec4 ([\strokec8 -\cf12 \strokec12 1\cf4 \strokec4 , \cf7 \strokec7 imp_features\cf4 \strokec4 .shape[\cf12 \strokec12 0\cf4 \strokec4 ]])\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 xlabel\cf4 \strokec4 (\cf11 \strokec11 'Importance'\cf4 \strokec4 )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 ylabel\cf4 \strokec4 (\cf11 \strokec11 'Feature'\cf4 \strokec4 )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 tight_layout\cf4 \strokec4 () \cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 savefig\cf4 \strokec4 (\cf7 \strokec7 cls_nm\cf4 \strokec4  \strokec8 +\strokec4  \cf11 \strokec11 "_feature_imp.png"\cf4 \strokec4 , \cf7 \strokec7 bbox_inches\cf4 \strokec8 =\cf11 \strokec11 'tight'\cf4 \strokec4 )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 show\cf4 \strokec4 ()\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 plot_feature_importance_coeff\cf4 \strokec4 (\cf7 \strokec7 best_log_reg_cv\cf4 \strokec4 , \cf7 \strokec7 loan_train_X\cf4 \strokec4 .columns, \cf7 \strokec7 cls_nm\cf4 \strokec8 =\cf11 \strokec11 "Logistic Regression"\cf4 \strokec4 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf10 \cb3 \strokec10 #Decision Tree - Plotting feature importance coefficients for the variables\'b6\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 # Defining a function to plot feature importance for trees\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 # INPUT: Used for Tree based Classifier\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 #        Feature Names\cf4 \cb1 \strokec4 \
\cf10 \cb3 \strokec10 # OUTPUT: A plot of top most features\cf4 \cb1 \strokec4 \
\
\pard\pardeftab720\partightenfactor0
\cf9 \cb3 \strokec9 def\cf4 \strokec4  \cf6 \strokec6 plot_feature_importance\cf4 \strokec4 (\cf7 \strokec7 model\cf4 \strokec4 , \cf7 \strokec7 Xnames\cf4 \strokec4 , \cf7 \strokec7 cls_nm\cf4 \strokec4  \strokec8 =\strokec4  \cf9 \strokec9 None\cf4 \strokec4 ):\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf4 \cb3     \cf10 \strokec10 # Measuring important features\cf4 \cb1 \strokec4 \
\cb3     \cf7 \strokec7 imp_features\cf4 \strokec4  \strokec8 =\strokec4  \cf5 \strokec5 pd\cf4 \strokec4 .\cf5 \strokec5 DataFrame\cf4 \strokec4 (\cf5 \strokec5 np\cf4 \strokec4 .\cf6 \strokec6 column_stack\cf4 \strokec4 ((\cf7 \strokec7 Xnames\cf4 \strokec4 , \cf7 \strokec7 model\cf4 \strokec4 .feature_importances_)), \cf7 \strokec7 columns\cf4 \strokec4  \strokec8 =\strokec4  [\cf11 \strokec11 'feature'\cf4 \strokec4 , \cf11 \strokec11 'importance'\cf4 \strokec4 ])\cb1 \
\cb3     \cf7 \strokec7 imp_features\cf4 \strokec4 [[\cf11 \strokec11 'importance'\cf4 \strokec4 ]] \strokec8 =\strokec4  \cf7 \strokec7 imp_features\cf4 \strokec4 [[\cf11 \strokec11 'importance'\cf4 \strokec4 ]].\cf6 \strokec6 astype\cf4 \strokec4 (\cf5 \strokec5 float\cf4 \strokec4 )\cb1 \
\cb3     \cf7 \strokec7 imp_features\cf4 \strokec4 [[\cf11 \strokec11 'abs_importance'\cf4 \strokec4 ]] \strokec8 =\strokec4  \cf7 \strokec7 imp_features\cf4 \strokec4 [[\cf11 \strokec11 'importance'\cf4 \strokec4 ]].\cf6 \strokec6 abs\cf4 \strokec4 ()\cb1 \
\cb3     \cf10 \strokec10 # Sort the features based on absolute value of importance\cf4 \cb1 \strokec4 \
\cb3     \cf7 \strokec7 imp_features\cf4 \strokec4  \strokec8 =\strokec4  \cf7 \strokec7 imp_features\cf4 \strokec4 .\cf6 \strokec6 sort_values\cf4 \strokec4 (\cf7 \strokec7 by\cf4 \strokec4  \strokec8 =\strokec4  [\cf11 \strokec11 'abs_importance'\cf4 \strokec4 ], \cf7 \strokec7 ascending\cf4 \strokec4  \strokec8 =\strokec4  [\cf12 \strokec12 1\cf4 \strokec4 ])\cb1 \
\cb3     \cb1 \
\cb3     \cf10 \strokec10 # Plot the feature importances\cf4 \cb1 \strokec4 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 figure\cf4 \strokec4 (\cf7 \strokec7 figsize\cf4 \strokec8 =\strokec4 (\cf12 \strokec12 10\cf4 \strokec4 , \cf12 \strokec12 16\cf4 \strokec4 ))\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 title\cf4 \strokec4 (\cf7 \strokec7 cls_nm\cf4 \strokec4  \strokec8 +\strokec4  \cf11 \strokec11 " - Feature Importance"\cf4 \strokec4 )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 barh\cf4 \strokec4 (\cf5 \strokec5 range\cf4 \strokec4 (\cf7 \strokec7 imp_features\cf4 \strokec4 .shape[\cf12 \strokec12 0\cf4 \strokec4 ]), \cf7 \strokec7 imp_features\cf4 \strokec4 [\cf11 \strokec11 'importance'\cf4 \strokec4 ],\cb1 \
\cb3             \cf7 \strokec7 color\cf4 \strokec8 =\cf11 \strokec11 "b"\cf4 \strokec4 , \cf7 \strokec7 align\cf4 \strokec8 =\cf11 \strokec11 "center"\cf4 \strokec4 )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 yticks\cf4 \strokec4 (\cf5 \strokec5 range\cf4 \strokec4 (\cf7 \strokec7 imp_features\cf4 \strokec4 .shape[\cf12 \strokec12 0\cf4 \strokec4 ]), \cf7 \strokec7 imp_features\cf4 \strokec4 [\cf11 \strokec11 'feature'\cf4 \strokec4 ], )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 ylim\cf4 \strokec4 ([\strokec8 -\cf12 \strokec12 1\cf4 \strokec4 , \cf7 \strokec7 imp_features\cf4 \strokec4 .shape[\cf12 \strokec12 0\cf4 \strokec4 ]])\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 xlabel\cf4 \strokec4 (\cf11 \strokec11 'Importance'\cf4 \strokec4 )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 ylabel\cf4 \strokec4 (\cf11 \strokec11 'Feature'\cf4 \strokec4 )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 tight_layout\cf4 \strokec4 () \cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 savefig\cf4 \strokec4 (\cf7 \strokec7 cls_nm\cf4 \strokec4  \strokec8 +\strokec4  \cf11 \strokec11 "_feature_imp.png"\cf4 \strokec4 , \cf7 \strokec7 bbox_inches\cf4 \strokec8 =\cf11 \strokec11 'tight'\cf4 \strokec4 )\cb1 \
\cb3     \cf5 \strokec5 plt\cf4 \strokec4 .\cf6 \strokec6 show\cf4 \strokec4 ()\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb3 \strokec6 plot_feature_importance\cf4 \strokec4 (\cf7 \strokec7 best_dec_tree_cv\cf4 \strokec4 , \cf7 \strokec7 loan_train_X\cf4 \strokec4 .columns, \cf7 \strokec7 cls_nm\cf4 \strokec8 =\cf11 \strokec11 'Decision Tree Classifier'\cf4 \strokec4 )\cb1 \
\
\
\
}